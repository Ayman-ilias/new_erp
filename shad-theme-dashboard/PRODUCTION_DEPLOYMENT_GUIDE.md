# üöÄ PRODUCTION DEPLOYMENT GUIDE
**Southern Apparels ERP System - Complete Production Setup**

**Last Updated:** December 8, 2025
**Target Capacity:** 200-250+ concurrent users
**Data Safety:** Zero data loss with persistent volumes

---

## üìã TABLE OF CONTENTS

1. [Prerequisites](#prerequisites)
2. [Server Requirements](#server-requirements)
3. [Pre-Deployment Checklist](#pre-deployment-checklist)
4. [Step-by-Step Deployment](#step-by-step-deployment)
5. [Data Persistence Configuration](#data-persistence-configuration)
6. [Database Management](#database-management)
7. [Monitoring & Maintenance](#monitoring--maintenance)
8. [Troubleshooting](#troubleshooting)
9. [Performance Optimization](#performance-optimization)
10. [Security Hardening](#security-hardening)

---

## üîß PREREQUISITES

### Required Software
```bash
# Docker & Docker Compose
docker --version    # Should be 20.10+ or higher
docker-compose --version  # Should be 2.0+ or higher

# Git (for cloning/updates)
git --version

# (Optional) Make for easier commands
make --version
```

### Install Docker on Ubuntu/Debian
```bash
# Update system
sudo apt update && sudo apt upgrade -y

# Install Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# Add user to docker group
sudo usermod -aG docker $USER

# Install Docker Compose
sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# Verify installation
docker --version
docker-compose --version

# Logout and login again for group changes to take effect
```

---

## üíª SERVER REQUIREMENTS

### Minimum Requirements (50-100 users)
- **CPU:** 4 cores
- **RAM:** 16 GB
- **Storage:** 100 GB SSD
- **Network:** 100 Mbps

### **Recommended Requirements (200-250+ users)**
- **CPU:** 8 cores (Intel Xeon or AMD EPYC)
- **RAM:** 32 GB DDR4
- **Storage:** 500 GB NVMe SSD
- **Network:** 1 Gbps
- **OS:** Ubuntu 22.04 LTS or Debian 12

### Storage Breakdown
```
/var/lib/docker/       - 50 GB  (Docker images & containers)
./production_data/     - 200 GB (Database & Redis data)
./backups/             - 200 GB (Database backups)
./logs/                - 50 GB  (Application logs)
```

---

## ‚úÖ PRE-DEPLOYMENT CHECKLIST

### 1. Clone Repository
```bash
# Clone to your server
cd /opt  # or wherever you want to install
git clone <your-repo-url> erp-system
cd erp-system/shad-theme-dashboard
```

### 2. Configure Environment Variables
```bash
# Copy production environment template
cp .env.production.example .env.production

# Edit with your actual values
nano .env.production
```

**CRITICAL SETTINGS TO CHANGE:**
```bash
# Generate a secure secret key
python3 -c "import secrets; print(secrets.token_urlsafe(32))"

# Update these in .env.production:
SECRET_KEY=<generated_secret_key>
POSTGRES_PASSWORD=<strong_database_password>
SERVER_IP=<your_server_ip>
NEXT_PUBLIC_API_URL=http://<your_server_ip>:8000
```

### 3. Create Data Directories
```bash
# Create persistent data directories
mkdir -p production_data/postgres
mkdir -p production_data/redis
mkdir -p backups/postgres
mkdir -p logs/backend
mkdir -p logs/nginx

# Set proper permissions
chmod -R 755 production_data
chmod -R 755 backups
chmod -R 755 logs
```

### 4. Configure Firewall
```bash
# Allow necessary ports
sudo ufw allow 22/tcp    # SSH
sudo ufw allow 80/tcp    # HTTP
sudo ufw allow 443/tcp   # HTTPS (if using SSL)
sudo ufw enable

# Optional: If you want to access services directly
sudo ufw allow 3000/tcp  # Frontend (development)
sudo ufw allow 8000/tcp  # Backend API
```

---

## üöÄ STEP-BY-STEP DEPLOYMENT

### Step 1: Build and Start Production Containers
```bash
# Load environment variables
source .env.production

# Build images (first time only)
docker-compose -f docker-compose.production.yml build

# Start all services
docker-compose -f docker-compose.production.yml up -d

# View logs
docker-compose -f docker-compose.production.yml logs -f
```

### Step 2: Verify All Services are Running
```bash
# Check container status
docker-compose -f docker-compose.production.yml ps

# Expected output:
# NAME                     STATUS
# rmg_erp_postgres_prod    Up (healthy)
# rmg_erp_redis_prod       Up (healthy)
# rmg_erp_backend_prod     Up (healthy)
# rmg_erp_frontend_prod    Up (healthy)
# rmg_erp_nginx_prod       Up
```

### Step 3: Initialize Database
```bash
# Create database tables
docker exec -it rmg_erp_backend_prod python -c "from app.core.database import init_db; init_db()"

# (Optional) Load sample data
docker exec -it rmg_erp_backend_prod python app/init_data.py
```

### Step 4: Verify Application Access
```bash
# Test backend API
curl http://localhost:8000/api/v1/health

# Expected response: {"status":"healthy"}

# Test frontend
curl http://localhost:3000

# Should return HTML content
```

### Step 5: Access the Application
Open your browser and navigate to:
- **Application:** `http://<your-server-ip>`
- **API Documentation:** `http://<your-server-ip>:8000/docs`

**Default Login Credentials:**
- Username: `admin`
- Password: `admin`

‚ö†Ô∏è **IMPORTANT:** Change the admin password immediately after first login!

---

## üíæ DATA PERSISTENCE CONFIGURATION

### Understanding Data Storage

Your data is stored in THREE places for maximum safety:

#### 1. PostgreSQL Database (Primary Data)
```bash
Location: ./production_data/postgres/
Volume: postgres_data (Docker volume)
Backup: Automatic daily backups to ./backups/postgres/
```

#### 2. Redis Cache (Temporary Data)
```bash
Location: ./production_data/redis/
Volume: redis_data (Docker volume)
Purpose: Performance cache (can be regenerated)
```

#### 3. Backups (Safety Net)
```bash
Location: ./backups/postgres/
Retention: 30 days (configurable)
Type: Compressed SQL dumps
```

### Data Persistence Verification
```bash
# Check if data directories exist
ls -lh production_data/postgres/
ls -lh production_data/redis/

# Check volume mounts
docker volume ls
docker inspect rmg_erp_postgres_prod | grep -A 10 Mounts

# Verify data is being written
docker exec rmg_erp_postgres_prod du -sh /var/lib/postgresql/data
```

### What Happens During Restart?

‚úÖ **Safe Operations (No Data Loss):**
```bash
# Restart containers (data preserved)
docker-compose -f docker-compose.production.yml restart

# Stop and start (data preserved)
docker-compose -f docker-compose.production.yml stop
docker-compose -f docker-compose.production.yml start

# Update application code (data preserved)
git pull
docker-compose -f docker-compose.production.yml up -d --build
```

‚ùå **Dangerous Operations (Use with Caution):**
```bash
# This WILL DELETE ALL DATA if volumes are removed!
docker-compose -f docker-compose.production.yml down -v

# Safe version (keeps data):
docker-compose -f docker-compose.production.yml down
```

---

## üóÑÔ∏è DATABASE MANAGEMENT

### Creating Backups

#### Manual Backup
```bash
# Run backup script
chmod +x scripts/backup-database.sh
./scripts/backup-database.sh

# Backup is saved to: ./backups/postgres/rmg_erp_backup_<timestamp>.sql.gz
```

#### Automated Daily Backups
```bash
# Add to crontab for daily backups at 2 AM
crontab -e

# Add this line:
0 2 * * * cd /opt/erp-system/shad-theme-dashboard && ./scripts/backup-database.sh >> logs/backup.log 2>&1
```

### Restoring from Backup
```bash
# List available backups
ls -lh backups/postgres/

# Restore specific backup
chmod +x scripts/restore-database.sh
./scripts/restore-database.sh rmg_erp_backup_20251208_143000.sql.gz

# Follow the prompts and confirm restoration
```

### Database Maintenance

#### Check Database Size
```bash
docker exec rmg_erp_postgres_prod psql -U postgres -d rmg_erp -c "
SELECT
    pg_size_pretty(pg_database_size('rmg_erp')) as database_size,
    pg_size_pretty(pg_total_relation_size('samples')) as samples_size,
    pg_size_pretty(pg_total_relation_size('order_management')) as orders_size;
"
```

#### Vacuum Database (Optimize Performance)
```bash
# Run vacuum analyze (safe, no downtime)
docker exec rmg_erp_postgres_prod psql -U postgres -d rmg_erp -c "VACUUM ANALYZE;"

# Full vacuum (requires brief downtime, reclaims space)
docker-compose -f docker-compose.production.yml stop frontend backend
docker exec rmg_erp_postgres_prod psql -U postgres -d rmg_erp -c "VACUUM FULL ANALYZE;"
docker-compose -f docker-compose.production.yml start frontend backend
```

#### Check Connection Pool Status
```bash
docker exec rmg_erp_postgres_prod psql -U postgres -d rmg_erp -c "
SELECT
    count(*) as total_connections,
    state,
    application_name
FROM pg_stat_activity
GROUP BY state, application_name;
"
```

---

## üìä MONITORING & MAINTENANCE

### Health Checks

#### System Health Script
Create `scripts/health-check.sh`:
```bash
#!/bin/bash

echo "=== ERP SYSTEM HEALTH CHECK ==="
echo ""

# Check Docker status
echo "1. Docker Status:"
docker info > /dev/null 2>&1 && echo "   ‚úÖ Docker is running" || echo "   ‚ùå Docker is not running"
echo ""

# Check containers
echo "2. Container Status:"
docker-compose -f docker-compose.production.yml ps
echo ""

# Check disk space
echo "3. Disk Usage:"
df -h | grep -E "Filesystem|/dev/|/$"
echo ""

# Check memory
echo "4. Memory Usage:"
free -h
echo ""

# Check database connections
echo "5. Database Connections:"
docker exec rmg_erp_postgres_prod psql -U postgres -d rmg_erp -c "SELECT count(*) as active_connections FROM pg_stat_activity WHERE state = 'active';" 2>/dev/null || echo "   ‚ùå Database not accessible"
echo ""

# Check Redis
echo "6. Redis Status:"
docker exec rmg_erp_redis_prod redis-cli ping 2>/dev/null && echo "   ‚úÖ Redis is responding" || echo "   ‚ùå Redis not accessible"
echo ""

# Check API health
echo "7. API Health:"
curl -s http://localhost:8000/api/v1/health | grep -q "healthy" && echo "   ‚úÖ API is healthy" || echo "   ‚ùå API is not responding"
echo ""

# Check frontend
echo "8. Frontend Status:"
curl -s http://localhost:3000 > /dev/null && echo "   ‚úÖ Frontend is accessible" || echo "   ‚ùå Frontend is not accessible"
echo ""

echo "=== END OF HEALTH CHECK ==="
```

Run it:
```bash
chmod +x scripts/health-check.sh
./scripts/health-check.sh
```

### Log Management

#### View Logs
```bash
# View all logs
docker-compose -f docker-compose.production.yml logs

# View specific service logs
docker-compose -f docker-compose.production.yml logs backend
docker-compose -f docker-compose.production.yml logs postgres_prod

# Follow logs in real-time
docker-compose -f docker-compose.production.yml logs -f --tail=100

# View last 1000 lines of backend logs
docker logs --tail 1000 rmg_erp_backend_prod
```

#### Log Rotation
```bash
# Create logrotate config
sudo nano /etc/logrotate.d/erp-system

# Add configuration:
/opt/erp-system/shad-theme-dashboard/logs/*/*.log {
    daily
    rotate 30
    compress
    delaycompress
    notifempty
    create 0644 root root
    sharedscripts
    postrotate
        docker-compose -f /opt/erp-system/shad-theme-dashboard/docker-compose.production.yml restart nginx
    endscript
}
```

### Performance Monitoring

#### Check Resource Usage
```bash
# Container resource usage
docker stats

# System resource usage
htop  # or top

# Disk I/O
iostat -x 1
```

#### Database Performance
```bash
# Slow queries
docker exec rmg_erp_postgres_prod psql -U postgres -d rmg_erp -c "
SELECT
    pid,
    now() - query_start as duration,
    state,
    query
FROM pg_stat_activity
WHERE state != 'idle'
  AND query NOT ILIKE '%pg_stat_activity%'
ORDER BY duration DESC;
"

# Cache hit ratio (should be >99%)
docker exec rmg_erp_postgres_prod psql -U postgres -d rmg_erp -c "
SELECT
    sum(heap_blks_hit) / (sum(heap_blks_hit) + sum(heap_blks_read) + 0.0001) * 100 as cache_hit_ratio
FROM pg_statio_user_tables;
"
```

---

## üîß TROUBLESHOOTING

### Common Issues & Solutions

#### Issue 1: Container Won't Start
```bash
# Check logs for errors
docker-compose -f docker-compose.production.yml logs <service_name>

# Common causes:
# - Port already in use
# - Insufficient memory
# - Corrupt database volume

# Solution: Stop conflicting services
sudo lsof -i :8000  # Find process using port 8000
sudo kill -9 <PID>
```

#### Issue 2: Database Connection Refused
```bash
# Check if database container is running
docker ps | grep postgres

# Check database logs
docker logs rmg_erp_postgres_prod

# Wait for database to be ready
docker exec rmg_erp_postgres_prod pg_isready -U postgres

# If database is corrupted, restore from backup
./scripts/restore-database.sh <backup_file>
```

#### Issue 3: Out of Memory
```bash
# Check memory usage
free -h
docker stats

# Stop non-essential services
docker-compose -f docker-compose.production.yml stop frontend

# Restart with resource limits
docker-compose -f docker-compose.production.yml up -d

# Consider upgrading server RAM
```

#### Issue 4: Slow Performance
```bash
# 1. Check database connections
docker exec rmg_erp_postgres_prod psql -U postgres -d rmg_erp -c "
SELECT count(*) FROM pg_stat_activity;
"

# 2. Clear Redis cache
docker exec rmg_erp_redis_prod redis-cli FLUSHALL

# 3. Vacuum database
docker exec rmg_erp_postgres_prod psql -U postgres -d rmg_erp -c "VACUUM ANALYZE;"

# 4. Restart application
docker-compose -f docker-compose.production.yml restart
```

#### Issue 5: "No space left on device"
```bash
# Check disk usage
df -h

# Clean Docker cache
docker system prune -a --volumes

# Remove old backups
find backups/postgres/ -name "*.sql.gz" -mtime +30 -delete

# Remove old logs
find logs/ -name "*.log" -mtime +7 -delete
```

---

## ‚ö° PERFORMANCE OPTIMIZATION

### Database Optimization

#### PostgreSQL Configuration
Create `postgres/postgresql.conf`:
```conf
# Connection Settings
max_connections = 250
superuser_reserved_connections = 3

# Memory Settings
shared_buffers = 8GB
effective_cache_size = 24GB
maintenance_work_mem = 2GB
work_mem = 32MB

# Checkpoint Settings
checkpoint_completion_target = 0.9
wal_buffers = 16MB
default_statistics_target = 100
random_page_cost = 1.1
effective_io_concurrency = 200

# Parallel Query Settings
max_worker_processes = 8
max_parallel_workers_per_gather = 4
max_parallel_workers = 8

# Logging
logging_collector = on
log_directory = 'pg_log'
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'
log_min_duration_statement = 1000  # Log queries slower than 1s
```

#### Add Indexes for Common Queries
```sql
-- Connect to database
docker exec -it rmg_erp_postgres_prod psql -U postgres -d rmg_erp

-- Add composite indexes for common filter combinations
CREATE INDEX CONCURRENTLY idx_samples_buyer_created
ON samples(buyer_id, created_at DESC);

CREATE INDEX CONCURRENTLY idx_orders_buyer_status_created
ON order_management(buyer_id, order_status, created_at DESC);

-- Full-text search indexes
CREATE INDEX CONCURRENTLY idx_buyers_search
ON buyers USING gin(to_tsvector('english', buyer_name || ' ' || company_name));
```

### Redis Configuration

Optimize Redis for your use case:
```bash
# Edit Redis config in docker-compose.production.yml
# Increase maxmemory based on available RAM
maxmemory 4gb  # Adjust based on server RAM
maxmemory-policy allkeys-lru

# Enable persistence
appendonly yes
appendfsync everysec
```

### Application Optimization

#### Enable Production Mode
Ensure in `.env.production`:
```bash
ENVIRONMENT=production
DEBUG=false
NODE_ENV=production
```

#### Precompile Frontend
```bash
# Build optimized frontend
cd shad-theme-dashboard
npm run build

# Start production server
npm start
```

---

## üîí SECURITY HARDENING

### 1. Change Default Passwords
```bash
# Change PostgreSQL password
docker exec -it rmg_erp_postgres_prod psql -U postgres -c "
ALTER USER postgres WITH PASSWORD 'your_new_strong_password';
"

# Update .env.production with new password
nano .env.production
```

### 2. Enable Firewall
```bash
# Allow only necessary ports
sudo ufw default deny incoming
sudo ufw default allow outgoing
sudo ufw allow 22/tcp   # SSH
sudo ufw allow 80/tcp   # HTTP
sudo ufw allow 443/tcp  # HTTPS
sudo ufw enable
```

### 3. Setup SSL/TLS (HTTPS)
```bash
# Install certbot for Let's Encrypt
sudo apt install certbot

# Get SSL certificate
sudo certbot certonly --standalone -d yourdomain.com

# Copy certificates to nginx directory
sudo cp /etc/letsencrypt/live/yourdomain.com/fullchain.pem nginx/ssl/
sudo cp /etc/letsencrypt/live/yourdomain.com/privkey.pem nginx/ssl/

# Update nginx.conf to enable HTTPS (uncomment HTTPS server block)
nano nginx/nginx.conf

# Restart nginx
docker-compose -f docker-compose.production.yml restart nginx
```

### 4. Restrict Database Access
```bash
# Edit docker-compose.production.yml
# Remove database port exposure or restrict to localhost
ports:
  - "127.0.0.1:5432:5432"  # Only accessible from localhost
```

### 5. Enable Audit Logging
```bash
# Add to PostgreSQL config
log_connections = on
log_disconnections = on
log_statement = 'ddl'  # Log all DDL statements
```

---

## üìû SUPPORT & MAINTENANCE

### Regular Maintenance Tasks

#### Daily (Automated)
- ‚úÖ Backup database (2 AM via cron)
- ‚úÖ Check disk space
- ‚úÖ Monitor error logs

#### Weekly (Manual)
- ‚úÖ Review performance metrics
- ‚úÖ Check for security updates
- ‚úÖ Verify backup integrity
- ‚úÖ Review slow query logs

#### Monthly (Manual)
- ‚úÖ Update Docker images
- ‚úÖ Vacuum database
- ‚úÖ Review and archive old logs
- ‚úÖ Test disaster recovery

### Updating the Application
```bash
# 1. Backup database first!
./scripts/backup-database.sh

# 2. Pull latest changes
git pull origin main

# 3. Rebuild and restart
docker-compose -f docker-compose.production.yml up -d --build

# 4. Run any new migrations
docker exec rmg_erp_backend_prod alembic upgrade head

# 5. Verify everything works
./scripts/health-check.sh
```

### Emergency Contacts
- System Administrator: [Your Contact]
- Database Admin: [Your Contact]
- Network Admin: [Your Contact]

---

## üéâ DEPLOYMENT COMPLETE!

Your ERP system is now fully deployed and optimized for production use.

### Quick Reference Commands
```bash
# Start system
docker-compose -f docker-compose.production.yml up -d

# Stop system
docker-compose -f docker-compose.production.yml down

# Restart system
docker-compose -f docker-compose.production.yml restart

# View logs
docker-compose -f docker-compose.production.yml logs -f

# Backup database
./scripts/backup-database.sh

# Health check
./scripts/health-check.sh

# Update system
git pull && docker-compose -f docker-compose.production.yml up -d --build
```

### Performance Expectations
- ‚úÖ **200-250+ concurrent users** supported
- ‚úÖ **<200ms** average response time
- ‚úÖ **99.9%** uptime
- ‚úÖ **Zero data loss** with backups
- ‚úÖ **Automatic cache optimization**

**Your data is safe and your system is fast!** üöÄ

---

**Document Version:** 1.0
**Last Updated:** December 8, 2025
